---
title: "Bias in Machine Learning"
date: 2018-02-05
categories: 
  - "data-science"
  - "machine-learning"
tags: 
  - "machine-learning"
  - "statistics"
  - "data-science"
  - "data"
coverImage: "pexels-photo-356043.jpeg"
---

You hear a lot about machine learning and how it's transforming industries, but there may be something about these algorithms you may not have heard - its biases.

A bias is favoring one group over the others and these machine learning algorithms are supposed to prevent decisions based on any type of bias a person would have. However, the machine learning models are only as good as the data that you give it. The historical data that we have has a built in bias that we need to address.

I came across an interesting talk from the 2017 [NIPS](https://nips.cc/) conference that goes over this very well.

<iframe src="//www.youtube.com/embed/fMym_BKWQzk?wmode=opaque&amp;enablejsapi=1" height="480" width="854" scrolling="no" frameborder="0" allowfullscreen></iframe>

There's also an interesting podcast episode of the [TED Radio Hour](https://www.npr.org/programs/ted-radio-hour/580617765/can-we-trust-the-numbers?showDate=2018-01-26) that goes over algorithmic bias.

<iframe src="https://www.npr.org/player/embed/580617998/580650782" width="100%" height="290" frameborder="0" scrolling="no" title="NPR embedded audio player"></iframe>

<iframe src="https://www.npr.org/player/embed/580619086/580651531" width="100%" height="290" frameborder="0" scrolling="no" title="NPR embedded audio player"></iframe>

Researchers know this is a problem in algorithms and they are actively doing research on how to better beat these biases from machine learning models. Until then, though, we would need to be diligent when testing our models to make sure these types of biases aren't integrated in our data.
